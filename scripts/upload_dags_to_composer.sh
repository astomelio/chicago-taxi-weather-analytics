#!/bin/bash
# Script para subir DAGs manualmente a Cloud Composer

set -e

PROJECT_ID="${GCP_PROJECT_ID:-brave-computer-454217-q4}"
REGION="${GCP_REGION:-us-central1}"
COMPOSER_ENV="chicago-taxi-composer"

echo "üîç Obteniendo informaci√≥n del entorno de Composer..."
BUCKET=$(gcloud composer environments describe "$COMPOSER_ENV" \
  --location "$REGION" \
  --project "$PROJECT_ID" \
  --format="value(config.dagGcsPrefix)" 2>/dev/null | sed 's|/dags||' || echo "")

if [ -z "$BUCKET" ]; then
  echo "‚ùå ERROR: No se pudo obtener el bucket de Composer"
  echo "   Verifica que Composer est√© creado y funcionando"
  exit 1
fi

echo "‚úÖ Bucket encontrado: $BUCKET"
echo "   Destino: gs://$BUCKET/dags/"
echo ""

# Verificar que los archivos existen
if [ ! -d "airflow/dags" ]; then
  echo "‚ùå ERROR: Directorio airflow/dags no existe"
  exit 1
fi

# Listar archivos que se van a subir
echo "üìã Archivos DAG encontrados:"
ls -la airflow/dags/*.py || echo "‚ö†Ô∏è  No se encontraron archivos .py"
echo ""

# Subir cada archivo .py individualmente
for dag_file in airflow/dags/*.py; do
  if [ -f "$dag_file" ]; then
    filename=$(basename "$dag_file")
    echo "üì§ Subiendo $filename..."
    gsutil cp "$dag_file" "gs://$BUCKET/dags/$filename"
    if [ $? -eq 0 ]; then
      echo "   ‚úÖ $filename subido correctamente"
    else
      echo "   ‚ùå Error subiendo $filename"
      exit 1
    fi
  fi
done

# Subir requirements.txt si existe
if [ -f "airflow/dags/requirements.txt" ]; then
  echo "üì§ Subiendo requirements.txt..."
  gsutil cp airflow/dags/requirements.txt "gs://$BUCKET/data/requirements.txt"
  echo "   ‚úÖ requirements.txt subido"
fi

echo ""
echo "‚úÖ Todos los DAGs subidos correctamente"
echo ""
echo "üîç Verificando DAGs en el bucket:"
gsutil ls "gs://$BUCKET/dags/*.py" || echo "‚ö†Ô∏è  No se encontraron DAGs en el bucket"
echo ""
echo "üìã Pr√≥ximos pasos:"
echo "1. Espera 1-2 minutos para que Airflow detecte los nuevos DAGs"
echo "2. Ve a la UI de Airflow y verifica que los DAGs aparezcan"
echo "3. Si hay errores, revisa los logs de parsing en Airflow"
